---
title: "Homework 6"
author: "Rose Killian"
output: github_document
---

### Loading libraries and data

```{r message= FALSE}
library(tidyverse)
library(modelr)
library(mgcv)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(8105)
```

# Problem 1

Load and clean the data for regression analysis (i.e. convert numeric to factor where appropriate, check for missing data, etc.).

```{r, data import tidy}
birth_df = 
  read_csv("data/birthweight.csv") %>% 
    janitor::clean_names() %>% 
  mutate(
    babysex = recode_factor(babysex, `1` = "male", `2` = "female"),
    frace = recode_factor(frace, `1` = "white", `2` = "black", `3` = "asian", `4` = "puerto rican", `8` = "other", `9` = "unknown"),
    mrace = recode_factor(mrace, `1` = "white", `2` = "black", `3` = "asian", `4` = "puerto rican", `8` = "other", `9` = "unknown"),
    malform = recode_factor(malform, `0` = "absent", `1` = "present")
  )

colSums(is.na(birth_df))
```

No missing observations


### Propose a regression model for birthweight.

After doing some general research on known risk-factors of low birth weight I will start to build a model by examining the effects of length at birth, head circumference, gestational age, sex, cigarettes smoked, income, presence of malformations, mother's age, parental race, and mother's pre-pregnancy BMI and weight gain on birth weight.

Based on the literature, I would like to include parity, number of previous low birth weight babies, and number of previous small for gestational age babies, but almost every value for parity is zero (total previous births = `r sum(pull(birth_df, parity))` with range `r min(pull(birth_df, parity))` - `r max(pull(birth_df, parity))`) and no observation in the sample has a previous low birth weight or small for gestational age baby. Therefore, these variables were excluded.

```{r, model 1.1}
my_mod = lm(bwt ~ blength + bhead + gaweeks + babysex + smoken + fincome + malform + momage + frace + mrace + ppbmi + wtgain, data = birth_df)

my_mod %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

Looks like `malform`, `momage` and `frace` are all non-significant. Removing them from the model and re-running:

```{r, model 1.2}
my_mod = lm(bwt ~ blength + bhead + gaweeks + babysex + smoken + fincome + mrace + ppbmi + wtgain, data = birth_df)

my_mod %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

birth_df %>% 
  modelr::add_residuals(my_mod) %>% 
  modelr::add_predictions(my_mod) %>% 
  ggplot(aes(x = pred, y = resid, alpha = 0.3)) +
  geom_point()
```

The plot of residuals vs. predicted values shows that the points are largely grouped around zero, indicating that the fit of the model is decent. 

Compare your model to two others:

* One using length at birth and gestational age as predictors (main effects only)

```{r, model 2}
main_mod = lm(bwt ~ blength + gaweeks, data = birth_df)

main_mod %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

birth_df %>% 
  modelr::add_residuals(main_mod) %>% 
  modelr::add_predictions(main_mod) %>% 
  ggplot(aes(x = pred, y = resid, alpha = 0.3)) +
  geom_point()
  
```


* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r, model 3}
interaction_mod = lm(bwt ~ blength * bhead * babysex, data = birth_df)

interaction_mod %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

birth_df %>% 
  modelr::add_residuals(interaction_mod) %>% 
  modelr::add_predictions(interaction_mod) %>% 
  ggplot(aes(x = pred, y = resid, alpha = 0.3)) +
  geom_point()
```

### Cross Validation

Make this comparison in terms of the cross-validated prediction error.

```{r, cv}
cv_df = 
  crossv_mc(birth_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df = 
  cv_df %>% 
  mutate(
   my_mod = map(train, ~lm(bwt ~ blength + bhead + gaweeks + babysex + smoken + fincome + mrace + ppbmi + wtgain, data = .x)),
   main_mod = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
   interaction_mod = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_mine = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
    rmse_main = map2_dbl(main_mod, test, ~rmse(model = .x, data = .y)),
    rmse_interaction = map2_dbl(interaction_mod, test, ~rmse(model = .x, data = .y))
  )
```

Plotting the results:

```{r, cv plot}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot()
```

My model has the lowest RMSE of all the models. By this metric my model performs much better than the main effects model and slightly better than the interaction model. The main effects model is the worst fit for the data with the highest RMSE.

# Problem 2

```{r, data import}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


```{r, bootstrapping}
boot_straps = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~tmin, data = .x)),
    glance = map(models, broom::glance),
    results = map(models, broom::tidy)
  ) %>%
  select(-strap, -models) %>% 
  unnest(results) %>% 
  unnest(glance, names_repair = "universal") %>% 
  select(.id, r.squared, term, estimate)

bootstrap_results = 
  boot_straps %>% 
    mutate(
      term = if_else(term == "tmin", "tmin", "Intercept")) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>% 
  mutate(
    log_b0_b1 = log(Intercept) + log(tmin)
  )
```

### Plotting

First let's look at r^2:

```{r, r square plot}
bootstrap_results %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() + 
  labs(
    x = "R-squared estimates",
    y = "Density"
  ) +
  ggtitle("Distribution of R squared in 5,000 bootstrap samples")
```

The distribution of r^2 estimates appears to follow a normal distribution and is centered around 0.91.

Now looking at log(β^0∗β^1):

```{r, log plot}
bootstrap_results %>% 
  ggplot(aes(x = log_b0_b1)) +
  geom_density() + 
  labs(
    x = "Log(B1*B0) estimates",
    y = "Density"
  ) +
  ggtitle("Distribution of Log(B0 * B1) in 5,000 bootstrap samples")
```

The distribution of log(β^0∗β^1) estimates appears to follow a normal distribution and is centered around 2.01

### 95% Confidence Intervals

Looking at r-squared first:

```{r, ci r square}
bootstrap_results %>% 
  summarise(
    lower = quantile(r.squared, 0.025),
    upper = quantile(r.squared, 0.975)
  ) %>% 
  knitr::kable()
```

The 95% confidence interval for the r-squared estimates is (0.89, 0.93).

Continuing with log(β^0∗β^1):

```{r, ci log}
bootstrap_results %>% 
  summarise(
    lower = quantile(log_b0_b1, 0.025),
    upper = quantile(log_b0_b1, 0.975)
  ) %>% 
  knitr::kable()
```

The 95% confidence interval for the log(β^0∗β^1) estimates is (1.96, 2.06).